@INPROCEEDINGS{Distante, 
 author={D. Distante and S. Huang}, 
 booktitle={20th Conference on Software Engineering Education Training (CSEET'07)}, 
 title={Challenges and Lessons Learned in Teaching Software Engineering and Programming to Hearing-Impaired Students}, 
 year={2007}, 
 pages={344-354}, 
 abstract={Teaching academic courses to students with disabilities is a challenging task, particularly for academics who are presented with the teaching requirements and needs that this implies, for the first time. Courses in the field of engineering and computer science, by requiring a lot of handson practices and teamwork, further exacerbate the situation as how to provide an effective learning experience for these disabled students. This situation requires a higher-level commitment than normal, from both the teachers and students. This paper presents the experience gained from teaching courses that involved hearing-impaired students of an undergraduate software engineering and a programming language course in two different universities. Some of the challenges faced by both instructors and the students are identified and some possible solutions are described.}, 
 keywords={computer science education;educational courses;handicapped aids;programming languages;software engineering;teaching;academic courses teaching;computer science;disabled students;hearing-impaired students;programming language course;programming teaching;software engineering teaching;undergraduate software engineering;Auditory system;Computer languages;Computer science;Education;Equal opportunities;Guidelines;Handicapped aids;Programming profession;Software engineering;Teamwork;hearing-impared students;programming languages;software engineering education}, 
 doi={10.1109/CSEET.2007.13}, 
 ISSN={1093-0175}, 
 month={July},}
@INPROCEEDINGS{Sargent, 
 author={D. Sargent and A. Malcolm}, 
 booktitle={Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP '79.}, 
 title={The presentation of continuous speech with synchronous printed text}, 
 year={1979}, 
 volume={4}, 
 pages={471-474}, 
 abstract={A communications problem encountered by most hearing impared people is their inability to understand spoken English. Since present technology appears unable to eliminate this speech perception problem, it is hoped that a better understanding of the relationship between printed and spoken English will permit the hearing impared person to better use their residual hearing. To aid in such instruction, a system is being developed which permits a fully synchronized presentation of recorded speech with its corresponding printed text. A series of computer algorithms are employed to segment the speech signal into syllable-like units, and to separate the corresponding printed text into syllables. The resulting data are then combined on a syllable-by-syllable basis, and any synchronization errors are corrected through operator intervention prior to the creation of the synchronized speech/text material for the classroom.}, 
 keywords={Auditory system;Computer errors;Deafness;Ear;Educational institutions;Error correction;Frequency synchronization;Keyboards;Speech;TV}, 
 doi={10.1109/ICASSP.1979.1170669}, 
 month={Apr},}
@INPROCEEDINGS{Coutinho, 
 author={F. Coutinho and R. O. Prates and L. Chaimowicz}, 
 booktitle={2011 Brazilian Symposium on Games and Digital Entertainment}, 
 title={An Analysis of Information Conveyed through Audio in an FPS Game and Its Impact on Deaf Players Experience}, 
 year={2011}, 
 pages={53-62}, 
 abstract={Mainstream games usually lack support for accessibility to deaf and hard of hearing people. The popular FPS game Half-Life 2 is an exception, in that it provides well constructed closed captions to players. In this paper, we performed a semiotic inspection on Half-Life 2, seeking to identify which strategies were used to convey information through audio. We also evaluated how the loss of information in each of them may impact players' experience. Our findings reveal that six different strategies are used and how they may compromise player experience.}, 
 keywords={computer games;handicapped aids;FPS game;Half-Life 2;deaf players experience;hearing people;mainstream games;semiotic inspection;Auditory system;Games;Gesture recognition;Handicapped aids;Inspection;Semiotics;Visualization;accessibility;deaf;games;hard of hearing;human-computer interaction;semiotic inspection}, 
 doi={10.1109/SBGAMES.2011.16}, 
 ISSN={2159-6654}, 
 month={Nov},}
@INPROCEEDINGS{Jones, 
 author={M. Jones and N. Bench and S. Ferons}, 
 booktitle={2014 2nd Workshop on Virtual and Augmented Assistive Technology (VAAT)}, 
 title={Vocabulary acquisition for deaf readers using augmented technology}, 
 year={2014}, 
 pages={13-15}, 
 abstract={Learning how to read for deaf and hard-of-hearing children poses a few challenges that have been explored over the years by various researchers [13]. We propose an innovative solution that may enhance the way deaf and hard-of-hearing children learn to read through the use of a head-mounted-display (HMD). Through the HMD, deaf and hard-of-hearing children will be able look up unfamilar printed words from a varity of sources and have an American Sign Language (ASL) video definition play back for them.}, 
 keywords={augmented reality;handicapped aids;helmet mounted displays;natural language processing;ASL;American sign language video definition;HMD;augmented technology;deaf children;deaf readers;hard-of-hearing children;head-mounted-display;vocabulary acquisition;Assistive technology;Cameras;Dictionaries;Education;Encoding;Gesture recognition;Prototypes;H.5.2 [Information Interfaces and Presentation]: User Interfaces — [H.1.2]: Information Systems — User/Machine Systems}, 
 doi={10.1109/VAAT.2014.6799461}, 
 month={March},}
@INPROCEEDINGS{Bouzid, 
 author={Y. Bouzid and M. A. Khenissi and M. Jemni}, 
 booktitle={2015 5th International Conference on Information Communication Technology and Accessibility (ICTA)}, 
 title={Designing a game generator as an educational technology for the deaf learners}, 
 year={2015}, 
 pages={1-6}, 
 abstract={Children today grow up in an exciting and changing world where the web technology, Internet, mobile phones, video games and computers surround all aspects of their daily lives. These digital technologies, in particular video games, have provided new opportunities for these kids to play, communicate with others, foster their imagination and also enhance their educational performance. Unfortunately, this can be a little more different for deaf and hard of hearing children, whose native language is Sign Language (SL). The most existing video games are not geared to the unique need of these hearing disabled: there have been, even timidly, few attempts that focusing on the development of accessible educational games that could meet the requirements necessary for deaf gamers and improve their educational potential. In this context, we present in this paper a design for an interactive game generator of an accessible and effective educational game target towards the deaf and hard of hearing children. The game is called MemoSign, it federates the use of the famous memory game and a 3D signing avatar to support learning the SL notation system SignWriting. The main goal of designing such game generator is to help teachers, even parents, to create many instances of MemoSign, in few steps without any programming language knowledge, with a view to foster and promote the vocabulary acquisition for deaf learners in both signed and spoken languages.}, 
 keywords={computer aided instruction;computer games;natural language processing;sign language recognition;3D signing avatar;MemoSign;SL notation system;deaf learners;digital technologies;educational game;educational technology;interactive game generator;sign language;video games;Assistive technology;Auditory system;Avatars;Computers;Games;Generators;Gesture recognition;assistive technology;children with hearing disabilities;computer game;educational game}, 
 doi={10.1109/ICTA.2015.7426914}, 
 month={Dec},}
@inproceedings{Hiraga,
 author = {Hiraga, Rumi and Hansen, Kjetil Falkenberg},
 title = {Sound Preferences of Persons with Hearing Loss Playing an Audio-based Computer Game},
 booktitle = {Proceedings of the 3rd ACM International Workshop on Interactive Multimedia on Mobile \&\#38; Portable Devices},
 series = {IMMPD '13},
 year = {2013},
 isbn = {978-1-4503-2399-4},
 location = {Barcelona, Spain},
 pages = {25--30},
 numpages = {6},
 url = {http://doi.acm.org.ezproxy.falmouth.ac.uk/10.1145/2505483.2505489},
 doi = {10.1145/2505483.2505489},
 acmid = {2505489},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {active listening, audio-based game, hearing impairment, hearing loss, music},} 
@inproceedings{Mielke,
 author = {Mielke, Matthias and Br\"{u}ck, Rainer},
 title = {A Pilot Study About the Smartwatch As Assistive Device for Deaf People},
 booktitle = {Proceedings of the 17th International ACM SIGACCESS Conference on Computers \&\#38; Accessibility},
 series = {ASSETS '15},
 year = {2015},
 isbn = {978-1-4503-3400-6},
 location = {Lisbon, Portugal},
 pages = {301--302},
 numpages = {2},
 url = {http://doi.acm.org.ezproxy.falmouth.ac.uk/10.1145/2700648.2811347},
 doi = {10.1145/2700648.2811347},
 acmid = {2811347},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assistive technology, deaf, hard of hearing, smartwatch},} 
@inproceedings{Namatame,
 author = {Namatame, Miki and Kusunoki, Fusako},
 title = {Learning Onomatopoeic Expressions by Animation},
 booktitle = {Proceedings of the International Conference on Advances in Computer Entertainment Technology},
 series = {ACE '07},
 year = {2007},
 isbn = {978-1-59593-640-0},
 location = {Salzburg, Austria},
 pages = {143--146},
 numpages = {4},
 url = {http://doi.acm.org.ezproxy.falmouth.ac.uk/10.1145/1255047.1255076},
 doi = {10.1145/1255047.1255076},
 acmid = {1255076},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {animation, hard-of-hearing, onomatopoeic, visualization},} 
@inproceedings{Lawrence,
 author = {Kushalnagar, Raja S. and Lawrence, David E. and Olsen, Elissa M.},
 title = {A Transition Community for Deaf and Hard of Hearing Students in Information Technology Programs},
 booktitle = {Proceedings of the 14th Annual ACM SIGITE Conference on Information Technology Education},
 series = {SIGITE '13},
 year = {2013},
 isbn = {978-1-4503-2239-3},
 location = {Orlando, Florida, USA},
 pages = {143--144},
 numpages = {2},
 url = {http://doi.acm.org.ezproxy.falmouth.ac.uk/10.1145/2512276.2512319},
 doi = {10.1145/2512276.2512319},
 acmid = {2512319},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {deaf and hard of hearing students, it programming sequence},} 
@inproceedings{Lasecki,
 author = {Lasecki, Walter S. and Miller, Christopher D. and Kushalnagar, Raja and Bigham, Jeffrey P.},
 title = {Legion Scribe: Real-time Captioning by the Non-experts},
 booktitle = {Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility},
 series = {W4A '13},
 year = {2013},
 isbn = {978-1-4503-1844-0},
 location = {Rio de Janeiro, Brazil},
 pages = {22:1--22:2},
 articleno = {22},
 numpages = {2},
 url = {http://doi.acm.org.ezproxy.falmouth.ac.uk/10.1145/2461121.2461151},
 doi = {10.1145/2461121.2461151},
 acmid = {2461151},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {captioning, crowdsourcing, deaf, hard of hearing, real-time human computation},} 

